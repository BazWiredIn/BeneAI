# Where to See Collected Data in BeneAI

## Quick Answer

When you press **"Start Session"**, data IS being collected! Here's where to see it:

### 1. **Browser Console (F12)** - Most Detailed View

Open DevTools Console and you'll see:

```
📊 [3:45:12 PM] Frame sent: {"count":1}
📊 [3:45:12 PM] Frame sent: {"count":2}
📊 [3:45:13 PM] Emotion received: {"state":"receptive","emotion":"Joy","confidence":"0.85","count":1}
📊 [3:45:14 PM] Frame sent: {"count":3}
📊 [3:45:14 PM] Emotion received: {"state":"receptive","emotion":"Joy","confidence":"0.87","count":2}
📊 [3:45:15 PM] Interval complete: {"state":"receptive","words":0,"count":1}
📊 [3:45:20 PM] Coaching advice: {"advice":"Great momentum! Investor is engaged...","state":"receptive","count":1}
```

**What you're seeing:**
- **Frame sent**: Video frames being captured and sent to backend (every ~333ms)
- **Emotion received**: Hume AI emotion analysis results (investor state + confidence)
- **Interval complete**: 1-second aggregated intervals
- **Coaching advice**: GPT-4 coaching recommendations (every 4.5 seconds)

---

### 2. **Debug Panel** - Real-Time Log

On the main UI (`http://localhost:8080`), expand the **"📊 Data Collection Log (Live)"** section at the bottom.

You'll see the same logs as console, but in the UI with timestamps.

---

### 3. **Status Bar** - Quick Stats

The status text (below video) shows live counters:

```
Active - Frames:125 | Emotions:42 | Intervals:15 | Advice:3
```

**What it means:**
- **Frames:125** → 125 video frames sent to backend
- **Emotions:42** → 42 emotion results received from Hume AI
- **Intervals:15** → 15 one-second intervals processed
- **Advice:3** → 3 coaching tips generated by GPT-4

---

### 4. **UI Panels** - Visual Feedback

#### Emotion Panel
Shows current investor state:
- **Label**: "Receptive", "Positive", "Skeptical", etc.
- **Confidence Bar**: Visual representation of detection confidence
- **Color coding**:
  - 🟢 Green = Receptive/Positive
  - 🟡 Yellow = Evaluative
  - 🔴 Red = Skeptical
  - ⚪ Gray = Neutral

#### Speech Metrics Panel
Shows speech analysis:
- **Words/Min**: Current speaking pace
- **Filler Words**: Count of "um", "uh", "like"
- **Pause Frequency**: Percentage of time pausing

#### AI Coaching Panel
Shows latest GPT-4 advice:
```
"Great momentum! The investor is highly engaged. Continue with your current approach."
```

---

### 5. **Backend Logs** - Server-Side Data

If backend is running in a terminal, you'll see:

```python
INFO: Processing frame with Hume AI for <client-id>
INFO: Emotion detected for <client-id>: receptive (Joy: 0.85)
INFO: Interval complete for <client-id>: receptive, 3 frames analyzed
INFO: Triggering LLM update for <client-id> with 5 intervals
INFO: Coaching advice sent for <client-id>: "Great momentum!..."
```

---

## What Data Is Being Collected?

### Per Video Frame (~3 FPS)
```json
{
  "type": "video_frame",
  "timestamp": 1234567890123,
  "data": "data:image/jpeg;base64,/9j/..."  // Base64 JPEG (~60KB)
}
```

### Emotion Results from Hume AI
```json
{
  "type": "emotion_result",
  "detected": true,
  "emotion": "Joy",
  "confidence": 0.85,
  "investor_state": "receptive",
  "all_emotions": {
    "Joy": 0.85,
    "Interest": 0.72,
    "Concentration": 0.68,
    // ... 45 more emotions
  },
  "top_emotions": [
    {"name": "Joy", "score": 0.85},
    {"name": "Interest", "score": 0.72},
    {"name": "Concentration", "score": 0.68}
  ],
  "timestamp": 1234567890500
}
```

### 1-Second Intervals
```json
{
  "type": "interval_complete",
  "interval": {
    "timestamp": 1234567890.5,
    "investor_state": "receptive",
    "top_emotions": [
      {"name": "Joy", "ema_score": 0.82, "trend": "increasing"},
      {"name": "Interest", "ema_score": 0.71, "trend": "stable"}
    ],
    "frames_count": 3,
    "faces_detected": 3,
    "words": ["I", "think", "this", "is", "great"],
    "full_text": "I think this is great"
  }
}
```

### GPT-4 Coaching Advice (every 4.5 seconds)
```json
{
  "type": "llm_context_update",
  "coaching_advice": "Great momentum! The investor is highly engaged. Continue with your current approach and maintain this energy.",
  "investor_state": "receptive",
  "state_emoji": "🟢",
  "state_color": "#22c55e",
  "context": {
    "intervals": [ /* last 5 intervals */ ],
    "summary": {
      "dominant_state": "receptive",
      "total_words": 23,
      "emotion_trends": {
        "Joy": "increasing",
        "Interest": "stable"
      }
    }
  }
}
```

---

## Troubleshooting: "Not Seeing Data?"

### Problem: Status shows "Frames:0"

**Solution:**
- Check webcam permission granted
- Check backend is running: `ps aux | grep "python main.py"`
- Check WebSocket connection in console (should see "Connected to BeneAI backend")

### Problem: "Emotions:0" even with Frames sent

**Solutions:**
1. **Check backend logs** for Hume AI errors
2. **Verify Hume API key** in `backend/.env`
3. **Check face detection** - ensure good lighting, face centered
4. **Backend logs should show**: `"Processing frame with Hume AI"`

### Problem: "Intervals:0" even with Emotions

**Solutions:**
- Wait at least 1 second for first interval
- Check backend logs for: `"Interval complete"`
- Ensure at least 1 frame with detected face

### Problem: "Advice:0" even with Intervals

**Solutions:**
- **Wait 5 seconds** - First advice comes after buffer is full (5 intervals)
- **Check OpenAI API key** in `backend/.env`
- **Check backend logs** for: `"Triggering LLM update"`
- **Verify OpenAI credits** available

---

## Summary: Data Flow Timeline

```
[0.0s] Press "Start Session"
[0.3s] Frame #1 sent → Hume AI → Emotion result received
[0.6s] Frame #2 sent → Hume AI → Emotion result received
[0.9s] Frame #3 sent → Hume AI → Emotion result received
[1.0s] ⏰ Interval #1 complete (3 frames aggregated)
[1.3s] Frame #4 sent...
[2.0s] ⏰ Interval #2 complete
[3.0s] ⏰ Interval #3 complete
[4.0s] ⏰ Interval #4 complete
[5.0s] ⏰ Interval #5 complete
[5.5s] 🧠 LLM coaching advice generated & displayed ✅
[9.5s] 🧠 Next coaching advice update
```

**Expected Counts After 10 Seconds:**
- Frames: ~30 (3 FPS × 10 sec)
- Emotions: ~30 (one per frame, if face detected)
- Intervals: 10 (one per second)
- Advice: 2 (first at 5s, second at 9.5s)

---

## Developer Tools

### View All WebSocket Messages

```javascript
// In browser console
app.wsClient.ws.addEventListener('message', (event) => {
    const data = JSON.parse(event.data);
    console.log('📥 WebSocket message:', data);
});
```

### View Latest Emotion Data

```javascript
// In browser console
console.log('Latest emotion:', app.latestEmotion);
// Output: {investorState: "receptive", primaryEmotion: "Joy", confidence: 0.85, ...}
```

### View Data Collection Stats

```javascript
// In browser console
console.log('Data stats:', app.dataStats);
// Output: {framesSent: 125, emotionsReceived: 42, intervalsReceived: 15, coachingAdviceReceived: 3}
```

---

## Where Data Is NOT Stored

**Important:** BeneAI is designed for real-time analysis with **zero persistence**:

❌ **No database** - All data is in-memory only
❌ **No files saved** - Video/audio never written to disk
❌ **No recordings** - Frames deleted after analysis
❌ **No logs persisted** - Backend logs go to stdout only

**Data lifecycle:**
1. Frame captured → Sent to backend → Analyzed by Hume → Result returned → Frame discarded
2. Interval aggregated → Used for LLM context → Dropped after 5 seconds
3. Coaching advice generated → Displayed in UI → Replaced by next advice

---

## Questions?

- **Not seeing frames sent?** → Check webcam permission
- **Not seeing emotions?** → Check Hume API key + face detection
- **Not seeing advice?** → Wait 5 seconds + check OpenAI API key
- **Want raw data?** → Open browser console (F12) for detailed logs

**Pro tip:** Keep the browser console open while running to see the complete data flow in real-time! 📊
